{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "7fa62a6b-afef-43f0-9bfa-84d1aecec5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736b68d9-2316-4685-9850-e9f8fd422753",
   "metadata": {},
   "source": [
    "### Fetching all the filepath to load the text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66600451-b6fe-49e8-97e5-2dd27c67f78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\n",
    "with open(\"shakespeare_scripts.txt\") as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07b5fd87-f9c7-4626-bcaa-f523e0db6f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset with length:  5536916\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset with length: \", len(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d8e010-dd11-43e4-829b-45f925c61365",
   "metadata": {},
   "source": [
    "## Vocabulary\n",
    "\n",
    "For this example we are working with characters instead of words or subwords \n",
    "Apart from character embedding we \n",
    "- Word Embedding \n",
    "- SubWord Embedding (Google uses SentencePiece)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ac3d3408-3da8-45a2-bd71-5151fe92ee38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab:  \t\n",
      " !$'(),-.0123456789:?ABCDEFGHIJKLMNOPQRSTUVWXYZ[]_abcdefghijklmnopqrstuvwxyz\n",
      "Vocab Size:  78\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(text))\n",
    "vocab_size = len(vocab)\n",
    "print(\"Vocab: \", \"\".join(vocab))\n",
    "print(\"Vocab Size: \", len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "21903864-7948-4768-a650-11b2f0b7fad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctoi = {v: k for k, v in enumerate(vocab)}\n",
    "itoc = {k:v for k, v in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "26045088-3afc-4d6f-b823-31d146526bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = lambda x: [ctoi[idx] for idx in x]\n",
    "decoder = lambda x: \"\".join([itoc[idx] for idx in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6a412351-6aac-4a19-8b05-ca6e9aacb630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Text:  [30, 56, 63, 63, 66]\n",
      "Decoded Text:  Hello\n"
     ]
    }
   ],
   "source": [
    "encoded_text = encoder(\"Hello\")\n",
    "print(\"Encoded Text: \", encoded_text)\n",
    "decoded_text = decoder(encoded_text)\n",
    "print(\"Decoded Text: \", decoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579d66a7-f234-45f5-b26e-80f8439b40e4",
   "metadata": {},
   "source": [
    "## Data Spliting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d9c859f0-56dd-489b-b8c4-cb6077a46c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9 * len(text))\n",
    "\n",
    "train_text = text[:n]\n",
    "test_text = text[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a5572cf3-40aa-405f-a10c-13e7e8f09255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Data Size:  5536916\n",
      "Train Data Size:  4983224\n",
      "Test Data Size:  553692\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Data Size: \", len(text))\n",
    "print(\"Train Data Size: \", len(train_text))\n",
    "print(\"Test Data Size: \", len(test_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152a1408-9020-4683-ae65-182be43c7709",
   "metadata": {},
   "source": [
    "### Convert data into tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dd01a4c1-6d4a-4d8c-b4be-7994809c1109",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torch.tensor(encoder(train_data), dtype=torch.long)\n",
    "test_data = torch.tensor(encoder(test_data), dtype = torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1245b884-f740-4c0b-b65e-494efbb43c0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([33, 31, 36, 29, 21,  1, 23, 25, 42,  2])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1cc18e-379f-4324-bbce-1a15e81b3df8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d684988a-a458-4be0-b52c-ecb08845a1a0",
   "metadata": {},
   "source": [
    "## Sequence Window Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "41501022-46bd-4a20-acce-f2114d50850a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([33, 31, 36, 29, 21,  1, 23, 25, 42])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5963973b-fa8f-4824-b7cd-5b05e72ae5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: tensor([33]), Target: 31\n",
      "Context: tensor([33, 31]), Target: 36\n",
      "Context: tensor([33, 31, 36]), Target: 29\n",
      "Context: tensor([33, 31, 36, 29]), Target: 21\n",
      "Context: tensor([33, 31, 36, 29, 21]), Target: 1\n",
      "Context: tensor([33, 31, 36, 29, 21,  1]), Target: 23\n",
      "Context: tensor([33, 31, 36, 29, 21,  1, 23]), Target: 25\n",
      "Context: tensor([33, 31, 36, 29, 21,  1, 23, 25]), Target: 42\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "\n",
    "for i in range(block_size):\n",
    "    \n",
    "    context = x[:i+1]\n",
    "    target = y[i]\n",
    "    print(f\"Context: {context}, Target: {target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcc330f-229d-4d79-9e99-f9b2868105cb",
   "metadata": {},
   "source": [
    "### Generate Batch Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e90e3a59-ed72-4e90-8ff9-f564df9d27cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 8\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "83a4b6a3-28ae-4d52-aaf0-425e6b725922",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(split):\n",
    "    \n",
    "    data = train_data if split == \"train\" else test_data\n",
    "    \n",
    "    rand_idx = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[idx: idx + block_size] for idx in rand_idx])\n",
    "    y = torch.stack([data[idx + 1: idx + block_size + 1] for idx in rand_idx])\n",
    "    return {\"x\": x, \"y\": y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c6508753-976a-4700-957b-c63bb70da37d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': tensor([[70, 71, 70,  2, 55, 60, 70, 67],\n",
       "         [64, 66, 69, 69, 66, 74,  2, 74],\n",
       "         [ 2, 71, 66,  2, 71, 59, 56,  2],\n",
       "         [66, 69,  2, 31,  8,  2, 65, 66]]),\n",
       " 'y': tensor([[71, 70,  2, 55, 60, 70, 67, 52],\n",
       "         [66, 69, 69, 66, 74,  2, 74, 59],\n",
       "         [71, 66,  2, 71, 59, 56,  2, 59],\n",
       "         [69,  2, 31,  8,  2, 65, 66, 69]])}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_batch(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "953f8e4b-019c-4dd2-a66b-7684426fb9ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2226723, 3333214, 4982009, 3996242])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "da9112ff-1042-47cd-bdb7-f98ca730f23b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer tensors of a single element can be converted to an index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer tensors of a single element can be converted to an index"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "67b4e6e9-edd6-492d-827f-576faedb1915",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiGramModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size):\n",
    "        super(BiGramModel, self).__init__()\n",
    "        self.emb = nn.Embedding(vocab_size, vocab_size)\n",
    "    \n",
    "    def forward(self, x, y = None):\n",
    "        logits = self.emb(x) # B x T x C\n",
    "        if y != None:\n",
    "            # Converting the Tensors as pytorch requires BT x C tensor\n",
    "            B, T, C = logits.shape\n",
    "            log = logits.view(B*T, C)\n",
    "            target = y.view(B*T)\n",
    "            loss = F.cross_entropy(log, target)\n",
    "            return logits, loss\n",
    "        return logits, None\n",
    "       \n",
    "    def generate(self, x, max_new_tokens):\n",
    "        \n",
    "        for _ in range(max_new_tokens):\n",
    "            \n",
    "            logits, loss = self(x)\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            \n",
    "            # Sampling from sample distribution \n",
    "            idx_next = torch.multinomial(probs, num_samples = 1)\n",
    "            \n",
    "            x = torch.cat((x, idx_next), dim=1)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "1fc077b8-2152-4025-8019-e09577af7d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BiGramModel(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "4b663e68-5e5d-4fd1-8d9d-22fcb0afbb73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits Shape:  torch.Size([64, 128, 78])\n",
      "Loss Shape:  tensor(4.8736, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "logits, loss = model(**generate_batch(\"test\"))\n",
    "\n",
    "print(\"Logits Shape: \", logits.shape)\n",
    "print(\"Loss Shape: \", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "0737cedc-ff16-4cf0-b5cb-c79ead7709c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial = torch.zeros(1, 1, dtype=torch.long)\n",
    "initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "36d72f63-cbd4-4a51-b5e3-ec19355bc97f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ti]t24A8_6Inp9a4R)BXTD94U6 hFj7S9Gh1]w(Fsdi\t6'jv1\n",
      "lqaLtmp,!53]x$b8Rll.v2yu2rU2dRwyQhJ5gOV8KLOPfYdzudm\n"
     ]
    }
   ],
   "source": [
    "print(decoder(model.generate(initial, 100)[0].numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4d4673-f6c1-4791-a3b0-d805d5cd8cc6",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "ee8cb4c5-41e6-4dc7-8068-121143d930a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.AdamW(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "4ba248e9-cf2a-4dca-aa4a-5c9fbabd38f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 128\n",
    "batch_size = 64\n",
    "\n",
    "epochs = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "e605240a-fb49-4483-8a51-04cf3d456dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [01:14<00:00, 134.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.4837432108402253 Validation Loss: 2.51157966175271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "final_loss = []\n",
    "final_validation_loss = []\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    idxs = generate_batch(\"train\")\n",
    "    logits, loss = model(**idxs)\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    final_loss.append(loss.item())\n",
    "    if epoch % 200:\n",
    "        with torch.no_grad():\n",
    "            _, loss = model(**generate_batch(\"val\"))\n",
    "            final_validation_loss.append(loss.item())\n",
    "        \n",
    "print(f\"Train Loss: {np.mean(final_loss)} Validation Loss: {np.mean(final_validation_loss)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "47a132fb-b59d-438c-9b69-35499a6b95e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tT:\n",
      "Buchixech marlet lo mblas.\n",
      "VIILLIUENI fal.\n",
      "CENDreane kodoraveepumfoundinthenca id her, avik memyore se sot hon O:\n",
      "CUCIVOLOHERDOFLIUEROUSTOLI lanamye ipe.\n",
      "ERES:\n",
      "Awe hena BELENA where y t camanfos upue owourenkilinfandusollablld d inounoul mst atere kn y t,\n",
      "ELLOThee w, ing.\n",
      "WI'lloe p'd, ary, IV:\n",
      "TAKIArobewow HE:\n",
      "MOLOR: t, ns bethis thttshe a t nocost! winliteseak ig bou'she t:\n",
      "CI PES:\n",
      "Y t t ourst l,\n",
      "A t I sw MARRENRY:\n",
      "SESer?\n",
      "Whe aselllitharkedilode tos amyelal atithtit fie Wo!\n",
      "G wnf IAND CAGLSTh torexpr test MICLVI s ure, w hat tace.\n",
      "GLI wne he, r Simunge hin ilcof alin sticourerasl s les at,\n",
      "GOS:\n",
      "G harengourichon.\n",
      "PUS PANE:\n",
      "God atll handy l shixim dice, k ongheshelt blldof thicu hefe walert dwor s\n",
      "WOClyorime ind Whorefon'sold se ain!'sth herolard Ja d myre RUCENESCK hesune\n",
      "BUERU:\n",
      "Whyof aro h be mo SA:\n",
      "INDGOTha me y, VALONGLUS:\n",
      "QUCHELOr ce.\n",
      "DUSTOTRBES:\n",
      "KINDO:\n",
      "S: IUCUThabre ppr LOMARI:\n",
      "SI igss nds f an bery, m s ggeshe soul hit matoreay tscomy, PULBONYON:\n",
      "FAENG mot\n",
      "HEN:\n",
      "Exerele arid CI\n"
     ]
    }
   ],
   "source": [
    "print(decoder(model.generate(initial, 1000)[0].numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd13955-917b-44db-9bf6-b1bceb26d343",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
