{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25bdf5d3-3ee0-439e-9b14-3c4e32e1e9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "from torch.nn import functional\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "973f7970-fbee-4a3d-a342-6f6bc340c359",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttentionLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, emb_size, key_size, value_size):\n",
    "        \"\"\"\n",
    "        This layer will take B x E as input and return \n",
    "        B X 1 as output.\n",
    "        \"\"\"\n",
    "        super(SelfAttentionLayer, self).__init__()        \n",
    "        self.emb_size = emb_size\n",
    "        \n",
    "        self.query_w = nn.Parameter(data = torch.Tensor(emb_size, key_size), requires_grad=True)\n",
    "        self.key_w = nn.Parameter(data = torch.Tensor(emb_size, key_size), requires_grad=True)\n",
    "        self.value_w = nn.Parameter(data = torch.Tensor(emb_size, value_size), requires_grad=True)\n",
    "        \n",
    "        self.query_w.data.uniform_(-1, 1)\n",
    "        self.key_w.data.uniform_(-1, 1)\n",
    "        self.value_w.data.uniform_(-1, 1)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        # Created Latent vectors\n",
    "        query = X @ self.query_w\n",
    "        key = X @ self.key_w\n",
    "        value = X @ self.value_w\n",
    "        \n",
    "        # Step 1: Take dot product query x key\n",
    "        query_key = query @ key.T\n",
    "        \n",
    "        # Step 2: Scale Down \n",
    "        query_key = query_key / np.sqrt(self.emb_size)\n",
    "        \n",
    "        # Step 3: Softmax \n",
    "        query_key = functional.softmax(query_key)\n",
    "        \n",
    "        # Step 4: Dot product with value\n",
    "        z = query_key @ value \n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "28c83a7f-6b0b-49e0-afe7-50add8ce7da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = SelfAttentionLayer(100, 64, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d1e0b6c9-3ace-4fb3-b28c-c72cabcef1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/by/dsdcsd5d2j76c5p_5jhbzdz40000gn/T/ipykernel_49829/1129152568.py:32: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  query_key = functional.softmax(query_key)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ -5.0843,   9.4798,   1.0584,  11.8069,   3.5864,   4.8195,   1.7043,\n",
       "          -7.1996,  -6.0194,  -0.6405,  -6.3124,  -8.5351,   3.1925,   5.4533,\n",
       "          -0.8233,  -0.4762,   4.7229,  10.0604,  -1.3713,   9.5223,  -4.7797,\n",
       "           4.7757,   0.1745,   4.2864,  -2.9410,  -0.5733,  -5.9982,   8.1013,\n",
       "           6.7948,  -6.3240,  -0.7363,   0.2341, -10.4797,  -0.3215,   0.7258,\n",
       "         -12.1739,   5.3160,   6.6976,  -0.1905,   5.4955,  -3.4306,  -5.4653,\n",
       "          11.9070,  -2.7301,   9.8852,   4.4781,  -6.9414,   8.9627,   4.1580,\n",
       "          -3.0651,  -2.2756,  -3.5140,   1.1860,   6.0247,  -2.8935,  12.2305,\n",
       "           6.0747,  -4.7928,   4.2265,   0.7376,  -2.5694,   3.5744,   2.0789,\n",
       "          -5.5691,   7.3652,   3.6363,   9.6546,  -9.6473,   3.9384,  -4.7080,\n",
       "           3.1698,  -6.0063,   2.4592,   0.5230,  -0.6025,  -9.3222,  -1.8954,\n",
       "           2.2409, -11.9186,   2.7639,  -1.0580,   0.5306,   7.4277,  -0.5028,\n",
       "           4.7346,   7.2282,   7.7415,   0.5907,  -8.5682,  -6.7216,  -0.2516,\n",
       "          -3.9435,   8.1528,  -0.5505,  -2.2833,   3.1841,  -2.6810,  -9.7344,\n",
       "          -1.1120,  -0.8894,  14.4085,   2.5903,   4.6446,  -9.8530,   8.9898,\n",
       "          -5.0135,   6.4321,   0.2023,   4.8360,   6.0215,  -0.8062,   5.3969,\n",
       "           0.8519,  -1.3908,  -5.5456,  -4.9919, -11.9377,  -7.0628,  -0.0978,\n",
       "           6.7790,   7.1763,  -1.5184,   7.5588,  -3.0087,  21.4916,   0.2381,\n",
       "           8.8745,  -0.3431]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention(torch.randn(1, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7f7cc2b0-0aa2-4fc4-8eec-754dd9b45093",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFNLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_layers, in_shape, out_shape, hidden_size=128):\n",
    "        super(FFNLayer, self).__init__()\n",
    "        self.l1 = nn.Linear(in_shape, hidden_size)\n",
    "        self.ff_list = nn.ModuleList([])\n",
    "        for x in range(1, n_layers - 1):\n",
    "            self.ff_list.append(nn.Linear(hidden_size, hidden_size))\n",
    "        self.out = nn.Linear(hidden_size, out_shape)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \n",
    "        x = self.l1(X)\n",
    "        for layer in self.ff_list:\n",
    "            x = functional.relu_(layer(x))\n",
    "        return self.out(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "aaebbe7f-0b3d-42ca-a8b4-5c933af6ef11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0704, -0.0370, -0.0603, -0.0845,  0.0380, -0.0399, -0.0572,  0.1146,\n",
       "         -0.0387, -0.0401, -0.0482,  0.0070, -0.0465,  0.0010,  0.0293, -0.1117,\n",
       "          0.0036,  0.0379, -0.0833,  0.0997,  0.0606,  0.0984,  0.0821,  0.0417,\n",
       "         -0.0312, -0.0207,  0.0182,  0.0750, -0.0110, -0.0030,  0.0473,  0.0360,\n",
       "         -0.0024,  0.0658, -0.0347, -0.1117, -0.0241,  0.0497,  0.0816,  0.0238,\n",
       "         -0.0602,  0.0186, -0.0024, -0.0583, -0.0557, -0.0231,  0.0231,  0.0183,\n",
       "          0.0404,  0.0948, -0.1180,  0.0753, -0.0825,  0.0212, -0.0092, -0.0043,\n",
       "         -0.1148,  0.1018, -0.0180,  0.0516, -0.0192,  0.0816,  0.0371,  0.0541]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff_layer = FFNLayer(5, 32, 64)\n",
    "ff_layer(torch.randn(1, 32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f982cac-67dc-41bd-95c5-1e9bb1610a08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "272872ec-ccfa-41f8-a36a-8734ffed1b4f",
   "metadata": {},
   "source": [
    "# Multi-Head Self Attention Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e74bc2-8f6a-4d03-a655-a5d51afa96a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28b121a-9cbb-46da-a4be-5e7c6e6da379",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "27a05229-13a8-4d30-b4e7-45f3fc14af71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttentionLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_heads, emb_size, key_size, value_size):\n",
    "        \n",
    "        super(MultiHeadAttentionLayer, self).__init__()\n",
    "        \n",
    "        assert n_heads > 0, \"Heads must be greater than or equal to 1\"\n",
    "        \n",
    "        self.n_heads = n_heads\n",
    "        self.emb_size = emb_size\n",
    "        self.key_size = key_size\n",
    "        self.value_size = value_size\n",
    "        self.latent_shape = emb_size/n_heads\n",
    "        \n",
    "        self.attention_heads = []\n",
    "        for i in range(n_heads):\n",
    "            qw = nn.Parameter(data = torch.Tensor(emb_size, key_size), requires_grad=True)\n",
    "            qw.data.uniform_(-1, 1)\n",
    "            \n",
    "            kw = nn.Parameter(data = torch.Tensor(emb_size, key_size), requires_grad=True)\n",
    "            kw.data.uniform_(-1, 1)\n",
    "            \n",
    "            vw = nn.Parameter(data = torch.Tensor(emb_size, value_size), requires_grad=True)\n",
    "            vw.data.uniform_(-1, 1)\n",
    "            \n",
    "            self.attention_heads.append({\"qw\": qw, \"kw\": kw, \"vw\": vw})\n",
    "            \n",
    "        # Output Weights will be of size (heads*value_dimension, embed_shape)\n",
    "        self.output_weight = nn.Parameter(data = torch.Tensor(np.int16(self.n_heads * value_size), emb_size), requires_grad=True)\n",
    "        self.output_weight.data.uniform_(-1, 1)\n",
    "        \n",
    "    \n",
    "    def forward(self, X):\n",
    "\n",
    "        output = []\n",
    "        for head in self.attention_heads:  \n",
    "            qw, kw, vw = head[\"qw\"], head[\"kw\"], head[\"vw\"]\n",
    "            query = X @ qw\n",
    "            key = X @ kw\n",
    "            value = X @ vw\n",
    "            query_key = query @ key.T\n",
    "            query_key = functional.softmax(query_key / np.sqrt(self.emb_size)) @ value\n",
    "            output.append(query_key)\n",
    "        return torch.hstack(output) @ self.output_weight\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e983bf-a773-4e7f-a765-eca8d6de513e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d56f6a4a-0bda-48fb-93ff-a1d5b8517f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = MultiHeadAttentionLayer(3, 128, 128, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c48350dd-bd5f-41d0-9d89-0aab1b8fa878",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/by/dsdcsd5d2j76c5p_5jhbzdz40000gn/T/ipykernel_49829/3330470574.py:42: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  query_key = functional.softmax(query_key / np.sqrt(self.emb_size)) @ value\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-49.1984,  56.5596, -17.9829,  ..., -47.5858,  34.1168, -39.6175],\n",
       "        [  4.5766, -43.2742,   6.3936,  ...,   3.8078, -63.8746,  96.5679],\n",
       "        [-52.6093, -29.1833, -42.1872,  ..., -32.5948, -64.6483, -59.6851],\n",
       "        ...,\n",
       "        [-19.1623, -75.5371,  -9.5427,  ...,   8.1399, -38.0727, -57.0843],\n",
       "        [-17.4054, -46.4293,  -1.0944,  ...,  33.5287, -23.9791, -28.7532],\n",
       "        [-40.0549, -10.8629, -19.8245,  ...,  -6.3601,  33.6071, -38.8377]],\n",
       "       grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention(torch.randn(10, 128))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965a772d-ab0e-4300-a961-87a9312942b4",
   "metadata": {},
   "source": [
    "# Encoder Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e4a26347-e91a-4f17-96fb-1e9be453a9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, emb_shape, out_shape, key_shape, value_shape, n_attention_heads = 1, ffn_layers = 3):\n",
    "        \n",
    "        super(Encoder, self).__init__()\n",
    "        self.emb_shape = emb_shape\n",
    "        self.out_shape = out_shape\n",
    "        self.fft_layers = ffn_layers\n",
    "        \n",
    "        self.attention_layer = MultiHeadAttentionLayer(n_attention_heads, emb_shape, key_shape, value_shape)\n",
    "        self.fft = FFNLayer(ffn_layers, emb_shape, out_shape)\n",
    "        self.norm_layer1 = nn.LayerNorm(emb_shape)\n",
    "        self.norm_layer2 = nn.LayerNorm(out_shape)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \n",
    "        \"\"\"\n",
    "        X: It will be positional encoded vector\n",
    "        \"\"\"\n",
    "        attention_resp = self.attention_layer(X)\n",
    "        \n",
    "        # Summing and normalizing Attention response and Position Vectors\n",
    "        summed_attention = attention_resp + X\n",
    "        normalized_resp = self.norm_layer1(summed_attention)\n",
    "        \n",
    "        # Getting FFT Response\n",
    "        fft_resp = self.fft(normalized_resp)\n",
    "        \n",
    "        # Sum and Normalize\n",
    "        fft_resp = normalized_resp + fft_resp\n",
    "        return self.norm_layer2(fft_resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a2b4e371-d03c-4573-93bb-bd424fa10be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/by/dsdcsd5d2j76c5p_5jhbzdz40000gn/T/ipykernel_49829/3330470574.py:42: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  query_key = functional.softmax(query_key / np.sqrt(self.emb_size)) @ value\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3327,  0.4116, -0.9861,  ..., -2.3578,  0.1315, -0.7881],\n",
       "        [-1.1328,  0.3602, -0.7221,  ...,  2.2564, -0.3207, -0.1107],\n",
       "        [-0.2970, -0.2225,  0.1057,  ...,  2.0895,  0.5040, -0.1919],\n",
       "        ...,\n",
       "        [-0.3056, -0.2487,  0.0823,  ...,  2.0816,  0.5152, -0.1851],\n",
       "        [-0.3353, -0.2736,  0.0922,  ...,  2.0629,  0.5189, -0.1954],\n",
       "        [ 0.5763,  0.5753,  0.6267,  ...,  0.2336, -0.0938, -0.5007]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = Encoder(128, 128, 64, 128)\n",
    "\n",
    "encoder(torch.randn(10, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0102b2eb-dec2-4671-90ab-ccb053cae108",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
